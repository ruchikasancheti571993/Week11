{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qH1dsiuW2rsg",
        "outputId": "33c35a0c-5c3f-47d2-b0f0-c9201d6a3696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357284 sha256=08face241155e71eb7569e97a280a624aa16e4491a16a9ba9df5f5bf475bb1ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn surprise\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the books dataset (bookId, title, authors, genres)\n",
        "books = pd.read_csv('/content/books.csv')\n",
        "\n",
        "# Load the ratings dataset (userId, bookId, rating)\n",
        "ratings = pd.read_csv('/content/ratings.csv')\n"
      ],
      "metadata": {
        "id": "2Rv9Unwj24Y4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean columns\n",
        "ratings.columns = ratings.columns.str.strip()"
      ],
      "metadata": {
        "id": "7hdtMyn9PmXb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load your data (adjust the path as needed)\n",
        "ratings = pd.read_csv(\"ratings.csv\")  # Ensure columns: user_id, book_id, rating\n",
        "books = pd.read_csv(\"books.csv\")  # Ensure columns: bookId, title\n",
        "\n",
        "# Create a sparse user-item interaction matrix\n",
        "interaction_matrix = ratings.pivot(index='user_id', columns='book_id', values='rating').fillna(0)\n",
        "sparse_interaction_matrix = csr_matrix(interaction_matrix.values)\n",
        "\n",
        "# Function to recommend books based on user similarity (computes similarity on demand)\n",
        "def recommend_books(user_id, top_n=5):\n",
        "    user_idx = user_id - 1  # Adjusting for zero-based indexing\n",
        "    user_vector = sparse_interaction_matrix[user_idx]\n",
        "\n",
        "    # Calculate cosine similarity with other users (only with non-zero rows to save memory)\n",
        "    similarity = cosine_similarity(user_vector, sparse_interaction_matrix)[0]\n",
        "\n",
        "    # Get indices of top similar users, excluding the target user\n",
        "    similar_user_indices = np.argsort(similarity)[-top_n-1:-1][::-1]\n",
        "\n",
        "    # Collect book recommendations from top similar users\n",
        "    recommended_books = []\n",
        "    for idx in similar_user_indices:\n",
        "        user_ratings = interaction_matrix.iloc[idx]\n",
        "        recommended_books.extend(user_ratings[user_ratings > 0].index.tolist())\n",
        "\n",
        "    # Remove duplicates and limit to top N recommendations\n",
        "    recommended_books = list(set(recommended_books))[:top_n]\n",
        "\n",
        "    # Map book IDs to book titles\n",
        "    book_titles = books[books['book_id'].isin(recommended_books)]['title'].values\n",
        "    return book_titles\n",
        "\n"
      ],
      "metadata": {
        "id": "Eq6jd6JadL1x"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Recommend top 5 books for user with ID 1\n",
        "recommended_books = recommend_books(1, top_n=5)\n",
        "print(\"Recommended Books for User 1:\")\n",
        "for book in recommended_books:\n",
        "    print(book)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u47U3uIEc08o",
        "outputId": "7be5a927-91a8-41dd-c6ec-8f83576b5a8d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended Books for User 1:\n",
            "The Hunger Games (The Hunger Games, #1)\n",
            "Harry Potter and the Sorcerer's Stone (Harry Potter, #1)\n",
            "Twilight (Twilight, #1)\n",
            "To Kill a Mockingbird\n",
            "The Great Gatsby\n"
          ]
        }
      ]
    }
  ]
}